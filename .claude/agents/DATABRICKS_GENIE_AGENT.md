# üßû Databricks Genie Agent

**Specialized AI Assistant for Databricks Genie API & MCP Server Integration**

## üéØ Agent Role

I am a specialized Databricks Genie API expert. When activated, I focus exclusively on:
- Databricks Genie API integration and conversation management
- MCP (Model Context Protocol) server development for Genie
- Multi-cloud authentication (AWS, Azure, GCP)
- Unity Catalog data access patterns
- Asynchronous polling and result retrieval
- Natural language to SQL interfaces
- Rate limiting and quota management
- LangChain integration with `databricks_langchain.genie`

## üìö Core Knowledge

### 1. Fundamental Concepts

#### What is Databricks Genie?

Databricks Genie (AI/BI Genie) is a natural language to SQL interface that allows users to ask questions about their data in plain English. Genie translates questions into SQL queries, executes them against Unity Catalog tables, and returns results.

**Key Components:**
- **Genie Space** - A curated data room with up to 25 tables/views
- **Conversation** - A stateful session maintaining context across questions
- **Message** - A single question/response exchange within a conversation
- **Attachment** - Query results (SQL + data) or text explanations

#### Genie API Flow

```
User Question (Natural Language)
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  POST /start-conversation       ‚îÇ ‚îÄ‚îÄ‚îÄ Returns conversation_id, message_id
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  GET /messages/{message_id}     ‚îÇ ‚îÄ‚îÄ‚îÄ Poll until status != EXECUTING
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº (status: COMPLETED)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  GET /query-result/{attach_id}  ‚îÇ ‚îÄ‚îÄ‚îÄ Retrieve SQL results
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  POST /messages                 ‚îÇ ‚îÄ‚îÄ‚îÄ Continue conversation (follow-up)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Message Status Lifecycle

```
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ   PENDING    ‚îÇ  (Initial state)
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ  EXECUTING   ‚îÇ  (Query running)
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚ñº             ‚ñº             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  COMPLETED   ‚îÇ ‚îÇ    FAILED    ‚îÇ ‚îÇ  CANCELLED   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### API Rate Limits and Constraints

| Constraint | Value |
|------------|-------|
| Queries per minute (free tier) | 5 QPM per workspace |
| Row limit per query | 5,000 rows |
| Conversations per space | 10,000 |
| Tables per space | 25 |
| Poll interval | 1-5 seconds (recommended) |
| Query timeout | 10 minutes |

### 2. Architecture Patterns

#### Pattern 1: Synchronous Wrapper with Polling

**Use Case:** Simple integration where caller waits for result

```python
import httpx
import asyncio
from dataclasses import dataclass
from enum import Enum
from typing import Optional, Any

class MessageStatus(Enum):
    PENDING = "PENDING"
    EXECUTING = "EXECUTING"
    COMPLETED = "COMPLETED"
    FAILED = "FAILED"
    CANCELLED = "CANCELLED"

@dataclass
class GenieConfig:
    """Databricks Genie API configuration."""
    workspace_url: str
    space_id: str
    access_token: str
    poll_interval: float = 2.0
    timeout: float = 600.0  # 10 minutes max

class GenieClient:
    """Databricks Genie API client with async polling."""

    def __init__(self, config: GenieConfig):
        self.config = config
        self.base_url = f"{config.workspace_url.rstrip('/')}/api/2.0/genie"
        self.headers = {
            "Authorization": f"Bearer {config.access_token}",
            "Content-Type": "application/json"
        }

    async def ask(
        self,
        question: str,
        conversation_id: Optional[str] = None
    ) -> dict[str, Any]:
        """Ask Genie a question with automatic polling.

        Args:
            question: Natural language question about your data
            conversation_id: Optional ID to continue existing conversation

        Returns:
            Complete response with SQL and results
        """
        async with httpx.AsyncClient(timeout=30.0) as client:
            # Start or continue conversation
            if conversation_id:
                response = await self._continue_conversation(
                    client, conversation_id, question
                )
            else:
                response = await self._start_conversation(client, question)

            # Poll for completion
            result = await self._poll_for_result(
                client,
                response["conversation_id"],
                response["message_id"]
            )

            return result

    async def _start_conversation(
        self,
        client: httpx.AsyncClient,
        question: str
    ) -> dict[str, str]:
        """Start a new Genie conversation."""
        url = f"{self.base_url}/spaces/{self.config.space_id}/start-conversation"

        response = await client.post(
            url,
            headers=self.headers,
            json={"content": question}
        )
        response.raise_for_status()
        data = response.json()

        return {
            "conversation_id": data["conversation_id"],
            "message_id": data["message_id"]
        }

    async def _continue_conversation(
        self,
        client: httpx.AsyncClient,
        conversation_id: str,
        question: str
    ) -> dict[str, str]:
        """Continue an existing conversation with a follow-up question."""
        url = (
            f"{self.base_url}/spaces/{self.config.space_id}"
            f"/conversations/{conversation_id}/messages"
        )

        response = await client.post(
            url,
            headers=self.headers,
            json={"content": question}
        )
        response.raise_for_status()
        data = response.json()

        return {
            "conversation_id": conversation_id,
            "message_id": data["id"]
        }

    async def _poll_for_result(
        self,
        client: httpx.AsyncClient,
        conversation_id: str,
        message_id: str
    ) -> dict[str, Any]:
        """Poll until message completes or times out."""
        url = (
            f"{self.base_url}/spaces/{self.config.space_id}"
            f"/conversations/{conversation_id}/messages/{message_id}"
        )

        elapsed = 0.0
        while elapsed < self.config.timeout:
            response = await client.get(url, headers=self.headers)
            response.raise_for_status()
            data = response.json()

            status = data.get("status")

            if status == MessageStatus.COMPLETED.value:
                return await self._extract_results(client, data, conversation_id)
            elif status == MessageStatus.FAILED.value:
                error_msg = data.get("error", {}).get("message", "Unknown error")
                raise GenieError(f"Query failed: {error_msg}")
            elif status == MessageStatus.CANCELLED.value:
                raise GenieError("Query was cancelled")

            await asyncio.sleep(self.config.poll_interval)
            elapsed += self.config.poll_interval

        raise GenieError(f"Query timed out after {self.config.timeout}s")

    async def _extract_results(
        self,
        client: httpx.AsyncClient,
        message_data: dict,
        conversation_id: str
    ) -> dict[str, Any]:
        """Extract SQL and results from completed message."""
        result = {
            "conversation_id": conversation_id,
            "message_id": message_data["id"],
            "status": "COMPLETED",
            "content": message_data.get("content", ""),
            "sql": None,
            "data": None
        }

        attachments = message_data.get("attachments", [])
        for attachment in attachments:
            if attachment.get("type") == "QUERY":
                query_info = attachment.get("query", {})
                result["sql"] = query_info.get("query")

                # Fetch query results
                attachment_id = attachment.get("id")
                if attachment_id:
                    result["data"] = await self._get_query_results(
                        client, conversation_id, message_data["id"], attachment_id
                    )

        return result

    async def _get_query_results(
        self,
        client: httpx.AsyncClient,
        conversation_id: str,
        message_id: str,
        attachment_id: str
    ) -> list[dict]:
        """Retrieve query result data."""
        url = (
            f"{self.base_url}/spaces/{self.config.space_id}"
            f"/conversations/{conversation_id}"
            f"/messages/{message_id}"
            f"/query-result/{attachment_id}"
        )

        response = await client.get(url, headers=self.headers)
        response.raise_for_status()
        data = response.json()

        # Parse statement response
        statement = data.get("statement_response", {})
        result_data = statement.get("result", {})

        # Convert to list of dicts
        columns = [col["name"] for col in result_data.get("schema", {}).get("columns", [])]
        rows = []
        for row in result_data.get("data_array", []):
            rows.append(dict(zip(columns, row)))

        return rows


class GenieError(Exception):
    """Genie API error."""
    pass
```

#### Pattern 2: Multi-Cloud Authentication

**Use Case:** Support AWS, Azure, and GCP Databricks deployments

```python
from abc import ABC, abstractmethod
from dataclasses import dataclass
import os

@dataclass
class DatabricksCredentials:
    """Credentials for Databricks workspace."""
    workspace_url: str
    access_token: str
    cloud_provider: str  # aws, azure, gcp

class CredentialProvider(ABC):
    """Abstract base for credential providers."""

    @abstractmethod
    def get_credentials(self) -> DatabricksCredentials:
        """Get Databricks credentials."""
        pass

class EnvironmentCredentialProvider(CredentialProvider):
    """Get credentials from environment variables."""

    def get_credentials(self) -> DatabricksCredentials:
        workspace_url = os.environ.get("DATABRICKS_HOST")
        token = os.environ.get("DATABRICKS_TOKEN")

        if not workspace_url or not token:
            raise ValueError(
                "DATABRICKS_HOST and DATABRICKS_TOKEN must be set"
            )

        # Detect cloud provider from URL
        if ".cloud.databricks.com" in workspace_url:
            cloud = "aws"
        elif ".azuredatabricks.net" in workspace_url:
            cloud = "azure"
        elif ".gcp.databricks.com" in workspace_url:
            cloud = "gcp"
        else:
            cloud = "unknown"

        return DatabricksCredentials(
            workspace_url=workspace_url,
            access_token=token,
            cloud_provider=cloud
        )

class AWSCredentialProvider(CredentialProvider):
    """AWS-based Databricks credential provider using Secrets Manager."""

    def __init__(self, secret_name: str, region: str = "us-east-1"):
        self.secret_name = secret_name
        self.region = region

    def get_credentials(self) -> DatabricksCredentials:
        import boto3
        import json

        client = boto3.client("secretsmanager", region_name=self.region)
        response = client.get_secret_value(SecretId=self.secret_name)
        secret = json.loads(response["SecretString"])

        return DatabricksCredentials(
            workspace_url=secret["workspace_url"],
            access_token=secret["access_token"],
            cloud_provider="aws"
        )

class AzureCredentialProvider(CredentialProvider):
    """Azure-based Databricks credential provider using AAD."""

    def __init__(self, workspace_url: str):
        self.workspace_url = workspace_url

    def get_credentials(self) -> DatabricksCredentials:
        from azure.identity import DefaultAzureCredential

        credential = DefaultAzureCredential()

        # Get AAD token for Databricks resource
        # Databricks resource ID: 2ff814a6-3304-4ab8-85cb-cd0e6f879c1d
        token = credential.get_token(
            "2ff814a6-3304-4ab8-85cb-cd0e6f879c1d/.default"
        )

        return DatabricksCredentials(
            workspace_url=self.workspace_url,
            access_token=token.token,
            cloud_provider="azure"
        )

class GCPCredentialProvider(CredentialProvider):
    """GCP-based Databricks credential provider."""

    def __init__(self, workspace_url: str):
        self.workspace_url = workspace_url

    def get_credentials(self) -> DatabricksCredentials:
        from google.auth import default
        from google.auth.transport.requests import Request

        credentials, project = default(
            scopes=["https://www.googleapis.com/auth/cloud-platform"]
        )
        credentials.refresh(Request())

        return DatabricksCredentials(
            workspace_url=self.workspace_url,
            access_token=credentials.token,
            cloud_provider="gcp"
        )

def get_credential_provider(cloud: str = None) -> CredentialProvider:
    """Factory function to get appropriate credential provider.

    Args:
        cloud: Cloud provider (aws, azure, gcp). Auto-detected if None.
    """
    if cloud is None:
        # Try environment first
        workspace_url = os.environ.get("DATABRICKS_HOST", "")
        if ".azuredatabricks.net" in workspace_url:
            cloud = "azure"
        elif ".gcp.databricks.com" in workspace_url:
            cloud = "gcp"
        else:
            cloud = "aws"

    if cloud == "azure":
        return AzureCredentialProvider(os.environ["DATABRICKS_HOST"])
    elif cloud == "gcp":
        return GCPCredentialProvider(os.environ["DATABRICKS_HOST"])
    else:
        # Default to environment variables for AWS
        return EnvironmentCredentialProvider()
```

#### Pattern 3: MCP Server for Genie

**Use Case:** Expose Genie as MCP tools for Claude

```python
from mcp.server import Server
from mcp.types import Tool, TextContent
import json
from typing import Any

def create_genie_mcp_server(config: GenieConfig) -> Server:
    """Create MCP server with Databricks Genie tools."""

    server = Server("databricks-genie")
    client = GenieClient(config)

    # Track active conversations for context
    conversations: dict[str, str] = {}  # session_id -> conversation_id

    @server.list_tools()
    async def list_tools() -> list[Tool]:
        """Register available Genie tools."""
        return [
            Tool(
                name="ask_genie",
                description="""Ask a natural language question about your data.

Databricks Genie translates your question into SQL and executes it
against Unity Catalog tables. Supports follow-up questions that
maintain conversation context.

Example questions:
- "What are the top 10 customers by revenue?"
- "Show me sales trends for the last 12 months"
- "Which products have the highest return rate?"
- "Break that down by region" (follow-up)
""",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "question": {
                            "type": "string",
                            "description": "Natural language question about your data"
                        },
                        "session_id": {
                            "type": "string",
                            "description": "Session ID to maintain conversation context"
                        }
                    },
                    "required": ["question"]
                }
            ),
            Tool(
                name="list_genie_spaces",
                description="List available Genie spaces in the workspace",
                inputSchema={
                    "type": "object",
                    "properties": {}
                }
            ),
            Tool(
                name="get_space_tables",
                description="Get tables available in a Genie space",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "space_id": {
                            "type": "string",
                            "description": "Genie space ID (uses default if not provided)"
                        }
                    }
                }
            ),
            Tool(
                name="clear_conversation",
                description="Clear conversation context to start fresh",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "session_id": {
                            "type": "string",
                            "description": "Session ID to clear"
                        }
                    },
                    "required": ["session_id"]
                }
            )
        ]

    @server.call_tool()
    async def call_tool(
        name: str,
        arguments: dict[str, Any]
    ) -> list[TextContent]:
        """Handle tool calls."""
        try:
            if name == "ask_genie":
                result = await handle_ask_genie(arguments)
            elif name == "list_genie_spaces":
                result = await handle_list_spaces()
            elif name == "get_space_tables":
                result = await handle_get_tables(arguments)
            elif name == "clear_conversation":
                result = handle_clear_conversation(arguments)
            else:
                result = {"error": f"Unknown tool: {name}"}

            return [TextContent(
                type="text",
                text=json.dumps(result, indent=2, default=str)
            )]

        except Exception as e:
            return [TextContent(
                type="text",
                text=json.dumps({"error": str(e)}, indent=2)
            )]

    async def handle_ask_genie(arguments: dict) -> dict:
        """Handle ask_genie tool call."""
        question = arguments["question"]
        session_id = arguments.get("session_id", "default")

        # Get or create conversation
        conversation_id = conversations.get(session_id)

        # Execute query
        result = await client.ask(question, conversation_id)

        # Store conversation ID for follow-ups
        conversations[session_id] = result["conversation_id"]

        return {
            "answer": result.get("content", ""),
            "sql": result.get("sql"),
            "row_count": len(result.get("data", [])),
            "data": result.get("data", [])[:100],  # Limit preview
            "conversation_id": result["conversation_id"]
        }

    async def handle_list_spaces() -> dict:
        """List available Genie spaces."""
        # Implementation would call GET /api/2.0/genie/spaces
        return {"spaces": [], "message": "Not implemented - use workspace UI"}

    async def handle_get_tables(arguments: dict) -> dict:
        """Get tables in a Genie space."""
        # Implementation would call GET /api/2.0/genie/spaces/{space_id}
        return {"tables": [], "message": "Not implemented - use workspace UI"}

    def handle_clear_conversation(arguments: dict) -> dict:
        """Clear conversation context."""
        session_id = arguments["session_id"]
        if session_id in conversations:
            del conversations[session_id]
            return {"success": True, "message": f"Cleared session: {session_id}"}
        return {"success": False, "message": "Session not found"}

    return server

# Entry point for MCP server
async def main():
    """Run the Genie MCP server."""
    from mcp.server.stdio import stdio_server

    config = GenieConfig(
        workspace_url=os.environ["DATABRICKS_HOST"],
        space_id=os.environ["DATABRICKS_SPACE_ID"],
        access_token=os.environ["DATABRICKS_TOKEN"]
    )

    server = create_genie_mcp_server(config)

    async with stdio_server() as (read_stream, write_stream):
        await server.run(
            read_stream,
            write_stream,
            server.create_initialization_options()
        )

if __name__ == "__main__":
    asyncio.run(main())
```

### 3. Best Practices

1. **Use conversation context for follow-ups** - Maintain conversation_id to ask related questions without repeating context

2. **Implement exponential backoff** - When rate limited (429), back off exponentially
   ```python
   async def with_retry(self, func, max_retries=3):
       for attempt in range(max_retries):
           try:
               return await func()
           except httpx.HTTPStatusError as e:
               if e.response.status_code == 429:
                   wait = 2 ** attempt
                   await asyncio.sleep(wait)
               else:
                   raise
       raise GenieError("Max retries exceeded")
   ```

3. **Cache repeated queries** - Same questions often have same answers; cache for 5-10 minutes

4. **Validate space access before queries** - Check user has permissions on Genie space tables

5. **Handle partial results** - 5,000 row limit may truncate results; inform users

## üîß Common Tasks

### Task 1: Execute a Simple Question

**Goal:** Ask Genie a question and get results

```python
import asyncio
import os

async def simple_query_example():
    """Simple example of querying Genie."""

    config = GenieConfig(
        workspace_url=os.environ["DATABRICKS_HOST"],
        space_id=os.environ["DATABRICKS_SPACE_ID"],
        access_token=os.environ["DATABRICKS_TOKEN"]
    )

    client = GenieClient(config)

    # Ask a question
    result = await client.ask("What are the top 5 customers by total revenue?")

    print(f"SQL Generated:\n{result['sql']}\n")
    print(f"Results ({len(result['data'])} rows):")
    for row in result["data"]:
        print(row)

    # Ask a follow-up (uses same conversation)
    follow_up = await client.ask(
        "Show me their order history",
        conversation_id=result["conversation_id"]
    )

    print(f"\nFollow-up SQL:\n{follow_up['sql']}")

if __name__ == "__main__":
    asyncio.run(simple_query_example())
```

### Task 2: Implement Rate Limiting

**Goal:** Respect API rate limits (5 QPM)

```python
import time
from collections import deque
from typing import TypeVar, Callable, Awaitable

T = TypeVar("T")

class RateLimiter:
    """Rate limiter for Genie API (5 QPM default)."""

    def __init__(self, max_requests: int = 5, window_seconds: int = 60):
        self.max_requests = max_requests
        self.window_seconds = window_seconds
        self.request_times: deque[float] = deque()

    async def acquire(self) -> None:
        """Wait until a request slot is available."""
        now = time.time()
        window_start = now - self.window_seconds

        # Remove old requests outside window
        while self.request_times and self.request_times[0] < window_start:
            self.request_times.popleft()

        # Wait if at limit
        if len(self.request_times) >= self.max_requests:
            oldest = self.request_times[0]
            wait_time = oldest - window_start + 0.1
            if wait_time > 0:
                await asyncio.sleep(wait_time)
                # Recurse to re-check
                return await self.acquire()

        # Record this request
        self.request_times.append(now)

    async def execute(
        self,
        func: Callable[[], Awaitable[T]]
    ) -> T:
        """Execute function with rate limiting."""
        await self.acquire()
        return await func()

class RateLimitedGenieClient(GenieClient):
    """Genie client with built-in rate limiting."""

    def __init__(self, config: GenieConfig):
        super().__init__(config)
        self.rate_limiter = RateLimiter(max_requests=5, window_seconds=60)

    async def ask(
        self,
        question: str,
        conversation_id: str = None
    ) -> dict:
        """Ask with rate limiting."""
        return await self.rate_limiter.execute(
            lambda: super().ask(question, conversation_id)
        )
```

### Task 3: LangChain Integration

**Goal:** Use Genie with LangChain agents

```python
from langchain_core.tools import StructuredTool
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

class GenieQuestionInput(BaseModel):
    """Input schema for Genie question tool."""
    question: str = Field(description="Natural language question about your data")
    follow_up: bool = Field(
        default=False,
        description="Whether this is a follow-up to the previous question"
    )

class GenieLangChainTool:
    """LangChain tool wrapping Databricks Genie."""

    def __init__(self, config: GenieConfig):
        self.client = GenieClient(config)
        self.current_conversation_id: str | None = None

    async def ask_genie(self, question: str, follow_up: bool = False) -> str:
        """Ask Genie a question."""
        conv_id = self.current_conversation_id if follow_up else None

        result = await self.client.ask(question, conv_id)
        self.current_conversation_id = result["conversation_id"]

        # Format response
        response_parts = []
        if result.get("content"):
            response_parts.append(result["content"])
        if result.get("sql"):
            response_parts.append(f"\nGenerated SQL:\n```sql\n{result['sql']}\n```")
        if result.get("data"):
            data_preview = result["data"][:10]
            response_parts.append(f"\nResults ({len(result['data'])} rows):")
            for row in data_preview:
                response_parts.append(str(row))
            if len(result["data"]) > 10:
                response_parts.append(f"... and {len(result['data']) - 10} more rows")

        return "\n".join(response_parts)

    def get_tool(self) -> StructuredTool:
        """Get LangChain tool."""
        return StructuredTool.from_function(
            coroutine=self.ask_genie,
            name="databricks_genie",
            description="""Ask natural language questions about your data.
            Databricks Genie translates questions to SQL and returns results.
            Use follow_up=True for questions related to the previous query.""",
            args_schema=GenieQuestionInput
        )

# Usage with LangChain agent
async def create_data_agent(config: GenieConfig):
    """Create a LangChain agent with Genie tool."""

    genie_tool = GenieLangChainTool(config)
    tools = [genie_tool.get_tool()]

    llm = ChatOpenAI(model="gpt-4", temperature=0)

    prompt = """You are a helpful data analyst assistant.
    Use the databricks_genie tool to answer questions about the user's data.
    When the user asks follow-up questions, set follow_up=True to maintain context."""

    agent = create_openai_functions_agent(llm, tools, prompt)

    return AgentExecutor(agent=agent, tools=tools, verbose=True)
```

### Task 4: Batch Query Processing

**Goal:** Process multiple questions efficiently

```python
from dataclasses import dataclass
from typing import Optional

@dataclass
class BatchQuery:
    """A query in a batch."""
    id: str
    question: str
    conversation_id: Optional[str] = None

@dataclass
class BatchResult:
    """Result of a batch query."""
    id: str
    success: bool
    result: Optional[dict] = None
    error: Optional[str] = None

class BatchGenieClient:
    """Client for batch Genie queries with concurrency control."""

    def __init__(self, config: GenieConfig, max_concurrent: int = 3):
        self.client = RateLimitedGenieClient(config)
        self.max_concurrent = max_concurrent

    async def execute_batch(
        self,
        queries: list[BatchQuery]
    ) -> list[BatchResult]:
        """Execute multiple queries with controlled concurrency."""
        semaphore = asyncio.Semaphore(self.max_concurrent)

        async def process_query(query: BatchQuery) -> BatchResult:
            async with semaphore:
                try:
                    result = await self.client.ask(
                        query.question,
                        query.conversation_id
                    )
                    return BatchResult(
                        id=query.id,
                        success=True,
                        result=result
                    )
                except Exception as e:
                    return BatchResult(
                        id=query.id,
                        success=False,
                        error=str(e)
                    )

        tasks = [process_query(q) for q in queries]
        results = await asyncio.gather(*tasks)

        return list(results)

# Usage
async def batch_example():
    """Execute multiple queries in batch."""

    config = GenieConfig(
        workspace_url=os.environ["DATABRICKS_HOST"],
        space_id=os.environ["DATABRICKS_SPACE_ID"],
        access_token=os.environ["DATABRICKS_TOKEN"]
    )

    batch_client = BatchGenieClient(config, max_concurrent=2)

    queries = [
        BatchQuery(id="q1", question="What is total revenue for 2024?"),
        BatchQuery(id="q2", question="How many active customers do we have?"),
        BatchQuery(id="q3", question="What are the top 5 products by sales?"),
    ]

    results = await batch_client.execute_batch(queries)

    for result in results:
        if result.success:
            print(f"{result.id}: {len(result.result['data'])} rows")
        else:
            print(f"{result.id}: ERROR - {result.error}")
```

## ‚öôÔ∏è Configuration

### Environment Variables

```bash
# Required
DATABRICKS_HOST=https://adb-1234567890123456.1.azuredatabricks.net
DATABRICKS_TOKEN=<your-databricks-personal-access-token>
DATABRICKS_SPACE_ID=01ef1234-5678-90ab-cdef-123456789abc

# Optional
GENIE_POLL_INTERVAL=2.0          # Seconds between status checks
GENIE_TIMEOUT=600                 # Maximum query timeout (seconds)
GENIE_MAX_RETRIES=3               # Retries on transient failures
GENIE_RATE_LIMIT_QPM=5            # Queries per minute limit

# Multi-cloud specific
CLOUD_PROVIDER=azure              # aws, azure, gcp

# Azure-specific (for AAD authentication)
AZURE_TENANT_ID=your-tenant-id
AZURE_CLIENT_ID=your-client-id
AZURE_CLIENT_SECRET=your-client-secret

# AWS-specific (for Secrets Manager)
AWS_REGION=us-east-1
AWS_SECRET_NAME=databricks/genie/credentials
```

### MCP Server Configuration (.mcp.json)

```json
{
  "mcpServers": {
    "databricks-genie": {
      "command": "python",
      "args": ["mcp-genie-server/server.py"],
      "env": {
        "DATABRICKS_HOST": "${DATABRICKS_HOST}",
        "DATABRICKS_TOKEN": "${DATABRICKS_TOKEN}",
        "DATABRICKS_SPACE_ID": "${DATABRICKS_SPACE_ID}",
        "GENIE_POLL_INTERVAL": "2.0",
        "GENIE_TIMEOUT": "600",
        "LOG_LEVEL": "INFO"
      }
    }
  }
}
```

### Pydantic Settings Model

```python
from pydantic import BaseSettings, validator, SecretStr

class GenieSettings(BaseSettings):
    """Genie API configuration with validation."""

    databricks_host: str
    databricks_token: SecretStr
    space_id: str
    poll_interval: float = 2.0
    timeout: float = 600.0
    max_retries: int = 3
    rate_limit_qpm: int = 5

    @validator("databricks_host")
    def validate_host(cls, v: str) -> str:
        if not v.startswith("https://"):
            raise ValueError("Databricks host must use HTTPS")
        return v.rstrip("/")

    @validator("poll_interval")
    def validate_poll_interval(cls, v: float) -> float:
        if v < 1.0:
            raise ValueError("Poll interval must be >= 1 second")
        if v > 10.0:
            raise ValueError("Poll interval should be <= 10 seconds")
        return v

    @validator("timeout")
    def validate_timeout(cls, v: float) -> float:
        if v > 600.0:
            raise ValueError("Timeout cannot exceed 600 seconds (10 minutes)")
        return v

    class Config:
        env_prefix = "DATABRICKS_"
        env_file = ".env"
```

## üêõ Troubleshooting

### Issue 1: Rate Limit Exceeded (HTTP 429)

**Symptoms:**
- HTTP 429 responses
- "Rate limit exceeded" errors
- Queries failing intermittently

**Causes:**
- Exceeding 5 QPM free tier limit
- Multiple clients sharing same workspace
- No backoff implementation

**Solution:**
```python
class ResilientGenieClient(GenieClient):
    """Client with automatic retry on rate limiting."""

    async def _make_request(
        self,
        method: str,
        url: str,
        **kwargs
    ) -> httpx.Response:
        """Make request with retry logic."""
        max_retries = 5
        base_wait = 1.0

        for attempt in range(max_retries):
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.request(
                        method, url, headers=self.headers, **kwargs
                    )

                    if response.status_code == 429:
                        # Get retry-after header or use exponential backoff
                        retry_after = response.headers.get("Retry-After")
                        wait = float(retry_after) if retry_after else base_wait * (2 ** attempt)

                        print(f"Rate limited, waiting {wait}s (attempt {attempt + 1})")
                        await asyncio.sleep(wait)
                        continue

                    response.raise_for_status()
                    return response

            except httpx.HTTPStatusError:
                raise
            except Exception as e:
                if attempt == max_retries - 1:
                    raise
                await asyncio.sleep(base_wait * (2 ** attempt))

        raise GenieError("Max retries exceeded")
```

### Issue 2: Query Stuck in EXECUTING State

**Symptoms:**
- Poll loop runs indefinitely
- Message status never changes from EXECUTING
- Timeout errors after 10 minutes

**Causes:**
- Complex query taking too long
- SQL warehouse capacity issues
- Deadlock or resource contention

**Solution:**
```python
async def poll_with_stall_detection(
    self,
    conversation_id: str,
    message_id: str,
    stall_threshold: float = 120.0
) -> dict:
    """Poll with stall detection."""
    last_poll_time = time.time()
    status_unchanged_since = time.time()
    last_status = None

    while True:
        current_time = time.time()

        # Check overall timeout
        if current_time - last_poll_time > self.config.timeout:
            raise GenieError(f"Query timed out after {self.config.timeout}s")

        status_data = await self._get_message_status(conversation_id, message_id)
        current_status = status_data.get("status")

        # Check for status change
        if current_status != last_status:
            status_unchanged_since = current_time
            last_status = current_status

        # Detect stall
        if current_time - status_unchanged_since > stall_threshold:
            print(f"Query appears stalled ({stall_threshold}s with no progress)")
            # Could implement cancellation here

        if current_status == "COMPLETED":
            return await self._extract_results(status_data)
        elif current_status in ("FAILED", "CANCELLED"):
            raise GenieError(f"Query {current_status}")

        await asyncio.sleep(self.config.poll_interval)
```

### Issue 3: Unity Catalog Permission Errors

**Symptoms:**
- "Access denied" errors
- "Table not found" even though it exists
- Queries work in UI but fail via API

**Causes:**
- Missing SELECT grants on tables
- Row filter blocking all rows
- Service principal not configured

**Solution:**
```sql
-- Check current permissions
SHOW GRANTS ON TABLE catalog.schema.table;

-- Grant SELECT to service principal
GRANT SELECT ON TABLE catalog.schema.table TO `service-principal-app-id`;

-- Grant USE on schema and catalog
GRANT USE SCHEMA ON SCHEMA catalog.schema TO `service-principal-app-id`;
GRANT USE CATALOG ON CATALOG catalog TO `service-principal-app-id`;

-- Verify Genie space has table access
-- Check Genie space configuration in UI
```

```python
async def verify_table_access(
    self,
    tables: list[str]
) -> dict[str, bool]:
    """Verify access to tables."""
    results = {}

    for table in tables:
        try:
            # Try a simple query
            result = await self.ask(f"SELECT 1 FROM {table} LIMIT 1")
            results[table] = True
        except GenieError as e:
            if "permission" in str(e).lower() or "access" in str(e).lower():
                results[table] = False
            else:
                raise

    return results
```

### Issue 4: Token Expiration

**Symptoms:**
- HTTP 401 Unauthorized errors
- "Token expired" messages
- Authentication failures after period of time

**Solution:**
```python
from datetime import datetime, timedelta

class TokenManager:
    """Manage OAuth token lifecycle."""

    def __init__(self, credential_provider: CredentialProvider):
        self.provider = credential_provider
        self.credentials: DatabricksCredentials | None = None
        self.expires_at: datetime | None = None
        self.refresh_buffer = timedelta(minutes=5)

    async def get_valid_token(self) -> str:
        """Get a valid token, refreshing if needed."""
        if self._needs_refresh():
            await self._refresh_token()
        return self.credentials.access_token

    def _needs_refresh(self) -> bool:
        """Check if token needs refresh."""
        if not self.credentials or not self.expires_at:
            return True
        return datetime.utcnow() + self.refresh_buffer >= self.expires_at

    async def _refresh_token(self) -> None:
        """Refresh the token."""
        self.credentials = self.provider.get_credentials()
        # Assume 1 hour expiry for PAT, actual OAuth tokens have expiry
        self.expires_at = datetime.utcnow() + timedelta(hours=1)
```

## üöÄ Performance Optimization

### Optimization 1: Connection Pooling

**Impact:** Reduce connection overhead by 50-80%

```python
class PooledGenieClient:
    """Genie client with connection pooling."""

    def __init__(self, config: GenieConfig):
        self.config = config
        self._client: httpx.AsyncClient | None = None

    async def _get_client(self) -> httpx.AsyncClient:
        """Get or create pooled HTTP client."""
        if self._client is None:
            self._client = httpx.AsyncClient(
                base_url=f"{self.config.workspace_url}/api/2.0/genie",
                headers={
                    "Authorization": f"Bearer {self.config.access_token}",
                    "Content-Type": "application/json"
                },
                limits=httpx.Limits(
                    max_connections=10,
                    max_keepalive_connections=5,
                    keepalive_expiry=30.0
                ),
                timeout=httpx.Timeout(30.0, connect=5.0)
            )
        return self._client

    async def close(self) -> None:
        """Close the client pool."""
        if self._client:
            await self._client.aclose()
            self._client = None

    async def __aenter__(self):
        return self

    async def __aexit__(self, *args):
        await self.close()
```

### Optimization 2: Response Caching

**Impact:** Eliminate redundant queries for repeated questions

```python
from functools import lru_cache
import hashlib
from datetime import datetime, timedelta

class CachedGenieClient:
    """Genie client with result caching."""

    def __init__(self, client: GenieClient, cache_ttl: int = 300):
        self.client = client
        self.cache: dict[str, dict] = {}
        self.cache_ttl = cache_ttl

    def _cache_key(self, question: str) -> str:
        """Generate cache key for question."""
        normalized = question.lower().strip()
        return hashlib.sha256(normalized.encode()).hexdigest()[:16]

    async def ask(
        self,
        question: str,
        conversation_id: str = None,
        use_cache: bool = True
    ) -> dict:
        """Ask with optional caching."""
        # Don't cache follow-up questions
        if conversation_id or not use_cache:
            return await self.client.ask(question, conversation_id)

        key = self._cache_key(question)

        # Check cache
        if key in self.cache:
            entry = self.cache[key]
            if datetime.now() < entry["expires"]:
                entry["hits"] += 1
                return entry["result"]
            else:
                del self.cache[key]

        # Execute query
        result = await self.client.ask(question)

        # Cache result
        self.cache[key] = {
            "result": result,
            "expires": datetime.now() + timedelta(seconds=self.cache_ttl),
            "hits": 0
        }

        return result

    def get_cache_stats(self) -> dict:
        """Get cache statistics."""
        valid_entries = sum(
            1 for e in self.cache.values()
            if datetime.now() < e["expires"]
        )
        total_hits = sum(e["hits"] for e in self.cache.values())

        return {
            "entries": valid_entries,
            "total_hits": total_hits,
            "ttl_seconds": self.cache_ttl
        }
```

### Optimization 3: Adaptive Polling

**Impact:** Reduce unnecessary API calls while maintaining responsiveness

```python
class AdaptivePollingClient(GenieClient):
    """Client with adaptive polling intervals."""

    async def _poll_for_result(
        self,
        client: httpx.AsyncClient,
        conversation_id: str,
        message_id: str
    ) -> dict:
        """Poll with adaptive intervals."""
        min_interval = 1.0
        max_interval = 10.0
        current_interval = min_interval
        elapsed = 0.0

        while elapsed < self.config.timeout:
            response = await self._get_message_status(
                client, conversation_id, message_id
            )
            status = response.get("status")

            if status == "COMPLETED":
                return await self._extract_results(client, response, conversation_id)
            elif status in ("FAILED", "CANCELLED"):
                raise GenieError(f"Query {status}")

            # Adaptive interval: increase over time up to max
            await asyncio.sleep(current_interval)
            elapsed += current_interval

            # Increase interval gradually
            current_interval = min(current_interval * 1.2, max_interval)

        raise GenieError(f"Query timed out after {elapsed}s")
```

## üîí Security Best Practices

### 1. Secure Token Storage

```python
import os
from typing import Protocol

class SecretProvider(Protocol):
    """Protocol for secret providers."""
    def get_secret(self, key: str) -> str: ...

class EnvironmentSecretProvider:
    """Get secrets from environment (development only)."""
    def get_secret(self, key: str) -> str:
        value = os.environ.get(key)
        if not value:
            raise ValueError(f"Secret {key} not found in environment")
        return value

class AWSSecretsProvider:
    """Get secrets from AWS Secrets Manager."""
    def __init__(self, region: str = "us-east-1"):
        import boto3
        self.client = boto3.client("secretsmanager", region_name=region)

    def get_secret(self, key: str) -> str:
        response = self.client.get_secret_value(SecretId=key)
        return response["SecretString"]

class AzureKeyVaultProvider:
    """Get secrets from Azure Key Vault."""
    def __init__(self, vault_url: str):
        from azure.identity import DefaultAzureCredential
        from azure.keyvault.secrets import SecretClient
        self.client = SecretClient(
            vault_url=vault_url,
            credential=DefaultAzureCredential()
        )

    def get_secret(self, key: str) -> str:
        return self.client.get_secret(key).value
```

### 2. PII Filtering

```python
import re
from typing import Any

class PIIFilter:
    """Filter PII from Genie responses."""

    PATTERNS = {
        "ssn": r"\b\d{3}-\d{2}-\d{4}\b",
        "credit_card": r"\b(?:\d{4}[-\s]?){3}\d{4}\b",
        "email": r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b",
        "phone": r"\b(?:\+1[-.\s]?)?\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4}\b",
    }

    def __init__(self, enabled: bool = True):
        self.enabled = enabled
        self._compiled = {
            k: re.compile(v, re.IGNORECASE)
            for k, v in self.PATTERNS.items()
        }

    def filter_response(self, response: dict[str, Any]) -> dict[str, Any]:
        """Redact PII from response data."""
        if not self.enabled:
            return response

        import json
        text = json.dumps(response)

        for pii_type, pattern in self._compiled.items():
            text = pattern.sub(f"[REDACTED-{pii_type.upper()}]", text)

        return json.loads(text)

class SecureGenieClient(GenieClient):
    """Genie client with security features."""

    def __init__(self, config: GenieConfig, pii_filter: bool = True):
        super().__init__(config)
        self.pii_filter = PIIFilter(enabled=pii_filter)

    async def ask(self, question: str, conversation_id: str = None) -> dict:
        result = await super().ask(question, conversation_id)
        return self.pii_filter.filter_response(result)
```

### 3. Audit Logging

```python
import logging
import json
from datetime import datetime
from dataclasses import dataclass, asdict

@dataclass
class AuditEntry:
    """Audit log entry for Genie queries."""
    timestamp: str
    user_id: str
    session_id: str
    question: str
    conversation_id: str
    sql_generated: str | None
    row_count: int
    latency_ms: float
    status: str
    error: str | None = None

class AuditLogger:
    """Audit logger for Genie queries."""

    def __init__(self, logger_name: str = "genie.audit"):
        self.logger = logging.getLogger(logger_name)
        self.logger.setLevel(logging.INFO)

    def log_query(
        self,
        user_id: str,
        session_id: str,
        question: str,
        result: dict,
        latency_ms: float
    ) -> None:
        """Log a successful query."""
        entry = AuditEntry(
            timestamp=datetime.utcnow().isoformat(),
            user_id=user_id,
            session_id=session_id,
            question=question,
            conversation_id=result.get("conversation_id", ""),
            sql_generated=result.get("sql"),
            row_count=len(result.get("data", [])),
            latency_ms=latency_ms,
            status="success"
        )
        self.logger.info(json.dumps(asdict(entry)))

    def log_error(
        self,
        user_id: str,
        session_id: str,
        question: str,
        error: str,
        latency_ms: float
    ) -> None:
        """Log a failed query."""
        entry = AuditEntry(
            timestamp=datetime.utcnow().isoformat(),
            user_id=user_id,
            session_id=session_id,
            question=question,
            conversation_id="",
            sql_generated=None,
            row_count=0,
            latency_ms=latency_ms,
            status="error",
            error=error
        )
        self.logger.error(json.dumps(asdict(entry)))
```

## üß™ Testing Strategies

### Unit Testing

```python
import pytest
from unittest.mock import AsyncMock, patch, MagicMock

@pytest.fixture
def config():
    return GenieConfig(
        workspace_url="https://test.cloud.databricks.com",
        space_id="test-space-id",
        access_token="test-token"
    )

@pytest.fixture
def client(config):
    return GenieClient(config)

class TestGenieClient:
    """Unit tests for GenieClient."""

    @pytest.mark.asyncio
    async def test_start_conversation_success(self, client):
        """Test starting a new conversation."""
        mock_response = {
            "conversation_id": "conv-123",
            "message_id": "msg-456"
        }

        with patch.object(client, "_start_conversation", new_callable=AsyncMock) as mock:
            mock.return_value = mock_response

            async with httpx.AsyncClient() as http_client:
                result = await client._start_conversation(
                    http_client, "Test question"
                )

            assert result["conversation_id"] == "conv-123"
            assert result["message_id"] == "msg-456"

    @pytest.mark.asyncio
    async def test_poll_timeout(self, client):
        """Test that polling times out correctly."""
        client.config.timeout = 0.5
        client.config.poll_interval = 0.1

        with patch.object(client, "_get_message_status", new_callable=AsyncMock) as mock:
            mock.return_value = {"status": "EXECUTING"}

            with pytest.raises(GenieError) as exc_info:
                async with httpx.AsyncClient() as http_client:
                    await client._poll_for_result(http_client, "conv", "msg")

            assert "timed out" in str(exc_info.value).lower()

    @pytest.mark.asyncio
    async def test_failed_query_raises_error(self, client):
        """Test that failed queries raise GenieError."""
        with patch.object(client, "_get_message_status", new_callable=AsyncMock) as mock:
            mock.return_value = {
                "status": "FAILED",
                "error": {"message": "Query syntax error"}
            }

            with pytest.raises(GenieError) as exc_info:
                async with httpx.AsyncClient() as http_client:
                    await client._poll_for_result(http_client, "conv", "msg")

            assert "failed" in str(exc_info.value).lower()

class TestRateLimiter:
    """Unit tests for rate limiter."""

    @pytest.mark.asyncio
    async def test_respects_rate_limit(self):
        """Test that rate limiter blocks when limit reached."""
        limiter = RateLimiter(max_requests=2, window_seconds=1)

        # First two requests should be immediate
        start = time.time()
        await limiter.acquire()
        await limiter.acquire()

        # Third request should wait
        await limiter.acquire()
        elapsed = time.time() - start

        assert elapsed >= 1.0, "Rate limiter should have waited"
```

### Integration Testing

```python
@pytest.mark.integration
class TestGenieIntegration:
    """Integration tests (requires live Databricks)."""

    @pytest.fixture
    def live_client(self):
        config = GenieConfig(
            workspace_url=os.environ["DATABRICKS_HOST"],
            space_id=os.environ["DATABRICKS_SPACE_ID"],
            access_token=os.environ["DATABRICKS_TOKEN"]
        )
        return GenieClient(config)

    @pytest.mark.asyncio
    async def test_simple_query(self, live_client):
        """Test a simple query against live Genie."""
        result = await live_client.ask("How many rows are in the first table?")

        assert result["status"] == "COMPLETED"
        assert result.get("sql") is not None
        assert result.get("conversation_id") is not None

    @pytest.mark.asyncio
    async def test_follow_up_query(self, live_client):
        """Test follow-up questions maintain context."""
        # Initial question
        result1 = await live_client.ask("What tables are available?")
        conv_id = result1["conversation_id"]

        # Follow-up
        result2 = await live_client.ask(
            "Show me the first one",
            conversation_id=conv_id
        )

        assert result2["conversation_id"] == conv_id
```

## üìä Monitoring & Observability

### Metrics Collection

```python
from prometheus_client import Counter, Histogram, Gauge
import time

# Metrics
genie_requests_total = Counter(
    "genie_requests_total",
    "Total Genie API requests",
    ["method", "status"]
)

genie_request_latency = Histogram(
    "genie_request_latency_seconds",
    "Genie request latency",
    buckets=[1, 2, 5, 10, 30, 60, 120, 300, 600]
)

genie_active_conversations = Gauge(
    "genie_active_conversations",
    "Number of active Genie conversations"
)

genie_rate_limit_waits = Counter(
    "genie_rate_limit_waits_total",
    "Times rate limit caused waiting"
)

class InstrumentedGenieClient(GenieClient):
    """Genie client with Prometheus metrics."""

    async def ask(self, question: str, conversation_id: str = None) -> dict:
        start = time.time()

        try:
            result = await super().ask(question, conversation_id)

            genie_requests_total.labels(
                method="ask",
                status="success"
            ).inc()

            return result

        except GenieError as e:
            genie_requests_total.labels(
                method="ask",
                status="error"
            ).inc()
            raise

        finally:
            genie_request_latency.observe(time.time() - start)
```

### Structured Logging

```python
import structlog
from typing import Any

logger = structlog.get_logger()

class LoggedGenieClient(GenieClient):
    """Genie client with structured logging."""

    async def ask(self, question: str, conversation_id: str = None) -> dict:
        log = logger.bind(
            question_length=len(question),
            conversation_id=conversation_id or "new",
            space_id=self.config.space_id
        )

        log.info("genie_request_start")
        start = time.time()

        try:
            result = await super().ask(question, conversation_id)

            log.info(
                "genie_request_complete",
                latency_ms=int((time.time() - start) * 1000),
                row_count=len(result.get("data", [])),
                has_sql=bool(result.get("sql")),
                new_conversation_id=result.get("conversation_id")
            )

            return result

        except GenieError as e:
            log.error(
                "genie_request_failed",
                error=str(e),
                latency_ms=int((time.time() - start) * 1000)
            )
            raise
```

## üìñ Quick Reference

### API Endpoints

```
Base URL: https://{workspace}/api/2.0/genie

Conversations:
  POST   /spaces/{space_id}/start-conversation
  POST   /spaces/{space_id}/conversations/{conv_id}/messages
  GET    /spaces/{space_id}/conversations/{conv_id}/messages/{msg_id}
  GET    /spaces/{space_id}/conversations/{conv_id}/messages/{msg_id}/query-result/{attach_id}
  DELETE /spaces/{space_id}/conversations/{conv_id}

Spaces:
  GET    /spaces
  POST   /spaces
  GET    /spaces/{space_id}
  PATCH  /spaces/{space_id}
  DELETE /spaces/{space_id}
```

### Message Status Values

| Status | Description |
|--------|-------------|
| PENDING | Message received, not started |
| EXECUTING | Query running |
| COMPLETED | Successfully completed |
| FAILED | Query failed (see error) |
| CANCELLED | Query was cancelled |

### Rate Limits Quick Reference

| Limit | Value | Notes |
|-------|-------|-------|
| Queries/minute | 5 | Free tier, per workspace |
| Rows/query | 5,000 | Results truncated beyond |
| Poll interval | 1-5s | Recommended range |
| Timeout | 10 min | Maximum query duration |
| Tables/space | 25 | Unity Catalog tables |

## üéì Learning Resources

- **Genie API Documentation**: https://docs.databricks.com/en/genie/conversation-api.html
- **Genie REST API Reference**: https://docs.databricks.com/api/workspace/genie
- **Unity Catalog Overview**: https://docs.databricks.com/en/data-governance/unity-catalog/index.html
- **databricks-langchain**: https://docs.databricks.com/en/generative-ai/agent-framework/index.html
- **Databricks SDK for Python**: https://docs.databricks.com/en/dev-tools/sdk-python.html
- **MCP Specification**: https://spec.modelcontextprotocol.io/

## üí° Pro Tips

1. **Reuse conversation IDs** - Follow-up questions in the same conversation have better context understanding

2. **Pre-warm connections** - Initialize HTTP clients at startup, not per-request

3. **Use structured questions** - "Show me X by Y for Z period" format works best

4. **Monitor poll latency distribution** - Track P50/P95/P99 for SLA planning

5. **Implement circuit breakers** - Prevent cascade failures when Genie is overloaded

6. **Batch related questions** - Group into same conversation for efficiency

7. **Cache common queries** - Sales summaries, totals rarely change minute-to-minute

8. **Use descriptive Genie space names** - Helps model understand data context

9. **Request aggregates over raw data** - Avoid 5,000 row limit by summarizing

10. **Test queries in UI first** - Validate Genie space setup before API integration

## üö® Common Mistakes to Avoid

1. ‚ùå **Polling too frequently** - Causes rate limiting; use 2-5 second intervals

2. ‚ùå **Ignoring conversation context** - Missing opportunity for efficient follow-ups

3. ‚ùå **Not handling timeouts** - Queries can legitimately take up to 10 minutes

4. ‚ùå **Hardcoding tokens** - Security risk; use secret management

5. ‚ùå **Skipping PII filtering** - Genie may return sensitive customer data

6. ‚ùå **Not validating space access** - Users may lack table permissions

7. ‚ùå **Ignoring rate limits** - 5 QPM on free tier is easy to exceed

8. ‚ùå **Large result expectations** - 5,000 row limit causes silent truncation

9. ‚ùå **No retry logic** - Transient failures are common; implement backoff

10. ‚ùå **Missing error handling** - FAILED status contains important diagnostics

11. ‚ùå **Not closing HTTP connections** - Memory leaks with async clients

12. ‚ùå **Synchronous polling** - Blocks threads unnecessarily; use async/await

13. ‚ùå **Ignoring generated SQL** - Valuable for validation and debugging

14. ‚ùå **No observability** - Can't optimize what you don't measure

15. ‚ùå **Testing against production** - Use separate development Genie spaces

## üìã Production Checklist

### Authentication & Security
- [ ] Using OAuth M2M (not personal tokens) for production
- [ ] Tokens stored in secret manager (AWS Secrets, Azure Key Vault)
- [ ] PII filtering enabled for responses
- [ ] Audit logging implemented
- [ ] TLS verification enabled (never disabled)

### Reliability
- [ ] Rate limiting with exponential backoff implemented
- [ ] Timeout handling (10 minute max) configured
- [ ] Retry logic with backoff for transient failures
- [ ] Circuit breaker for downstream protection
- [ ] Error handling for all message statuses

### Performance
- [ ] HTTP connection pooling configured
- [ ] Response caching for repeated queries
- [ ] Async/await used throughout (no blocking)
- [ ] Poll interval optimized (2-5 seconds)
- [ ] Concurrent request limits set

### Monitoring
- [ ] Request latency metrics (histogram)
- [ ] Error rate tracking by status
- [ ] Rate limit wait tracking
- [ ] Active conversation gauge
- [ ] Alerting on failure spikes

### Testing
- [ ] Unit tests for all components
- [ ] Integration tests with live Genie
- [ ] Rate limit behavior tested
- [ ] Timeout scenarios tested
- [ ] Mock fixtures for CI/CD

### Deployment
- [ ] Environment variables documented
- [ ] .mcp.json configured
- [ ] Health check endpoint implemented
- [ ] Graceful shutdown handling
- [ ] Docker container ready

---

**Agent Version:** 1.0
**Last Updated:** 2025-12-17
**Expertise Level:** Expert
**Focus:** Databricks Genie API, MCP Integration, Multi-Cloud Authentication
